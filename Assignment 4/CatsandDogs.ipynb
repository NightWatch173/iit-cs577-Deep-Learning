{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N7Q4krB4BBDa"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "filename = \"data1.zip\"\n",
    "\n",
    "with ZipFile(filename,'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkeEbdbLBQRh"
   },
   "outputs": [],
   "source": [
    "# import the necessary pacakges\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import Model\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.test.is_built_with_cuda())\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imutils import paths\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nEhJQfvBXCP"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4I9DfzxuBbQU"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", \n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "diVe5tJ7Bq8Z"
   },
   "outputs": [],
   "source": [
    "## Training using Generators\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = \"data1//train\"\n",
    "val_dir = \"data1//val\"\n",
    "test_dir = \"data1//test\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150,150),batch_size=32,class_mode=\"binary\")\n",
    "validation_generator = val_datagen.flow_from_directory(val_dir,target_size=(150,150),batch_size=32,class_mode=\"binary\")\n",
    "test_generator = test_datagen.flow_from_directory(val_dir,target_size=(150,150),batch_size=32,class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4KLhu-X5BjMU"
   },
   "outputs": [],
   "source": [
    "train_steps_per_epoch = np.math.ceil(train_generator.samples / train_generator.batch_size)\n",
    "val_steps_per_epoch = np.math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
    "\n",
    "result = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=train_steps_per_epoch,\n",
    "                             epochs=40,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=val_steps_per_epoch,\n",
    "                             workers = 10)\n",
    "model.save(\"CatsAndDogs.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7RESdGKpB-_i"
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "loss = result.history['loss']\n",
    "val_loss = result.history['val_loss']\n",
    "epochs = range(1,len(loss)+1)\n",
    "plt.plot(epochs,loss,'bo',label='Training loss') # blue dots\n",
    "plt.plot(epochs,val_loss,'b',label='Validation loss') # blue line\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the training and validation accuracy\n",
    "plt.clf()\n",
    "acc_values = result.history['accuracy']\n",
    "val_acc_values = result.history['val_accuracy']\n",
    "plt.plot(epochs,acc_values,'bo',label='Training accuracy')\n",
    "plt.plot(epochs,val_acc_values,'b',label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4GH66mrECCtp"
   },
   "outputs": [],
   "source": [
    "# Test Eval\n",
    "test_steps_per_epoch = np.math.ceil(test_generator.samples / test_generator.batch_size)\n",
    "final_test_loss, final_test_acc = model.evaluate_generator(\n",
    "    test_generator,\n",
    "    steps=test_steps_per_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3g_dMsmaCGB2"
   },
   "outputs": [],
   "source": [
    "# Test Plot\n",
    "print(\"Test Accuracy : \", final_test_acc * 100)\n",
    "print(\"Test Loss : \", final_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ZEBHbYGBjiz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "datagen = ImageDataGenerator(rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest')\n",
    "\n",
    "train_cats_dir = \"data1//train//cats\"\n",
    "fnames = [os.path.join(train_cats_dir,fname) for fname in os.listdir(train_cats_dir)]\n",
    "img_path = fnames[3]\n",
    "img = image.load_img(img_path,target_size = (150,150))\n",
    "x = image.img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "i = 0\n",
    "for batch in datagen.flow(x,batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i +=1\n",
    "    if i%4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9N59e_GTGVZa"
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(150,150,3)\n",
    ")\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtcJwp8iGbqA"
   },
   "outputs": [],
   "source": [
    "conv_base.trainable = False\n",
    "\n",
    "modelvgg_froz = models.Sequential()\n",
    "modelvgg_froz.add(conv_base)\n",
    "modelvgg_froz.add(layers.Flatten())\n",
    "modelvgg_froz.add(layers.Dense(512, activation='relu'))\n",
    "modelvgg_froz.add(layers.Dense(1, activation='sigmoid'))\n",
    "modelvgg_froz.summary()\n",
    "\n",
    "modelvgg_froz.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yd3Qj72OGrEL"
   },
   "outputs": [],
   "source": [
    "history_vgg_frozen=modelvgg_froz.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps_per_epoch\n",
    ")\n",
    "modelvgg_froz.save(\"CatsAndDogs_frozen.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sF6MLQBKxdr"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hist_dict = history_vgg_frozen.history\n",
    "print(hist_dict.keys())\n",
    "loss_values = hist_dict['loss']\n",
    "val_loss_values = hist_dict['val_loss']\n",
    "epochs = range(1, len(hist_dict['val_loss']) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Frozen_loss.png')\n",
    "\n",
    "plt.clf()\n",
    "acc_values = hist_dict['acc']\n",
    "val_acc_values = hist_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training Acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation Acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Frozen_acc.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4UHBbDN7gS3V"
   },
   "outputs": [],
   "source": [
    "# Test Eval\n",
    "frozen_test_loss, frozen_test_acc = modelvgg_froz.evaluate_generator(\n",
    "    test_generator,\n",
    "    steps=test_steps_per_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WAeYN4tIUjw8"
   },
   "outputs": [],
   "source": [
    "# Test Plot\n",
    "print(\"Test Accuracy : \", frozen_test_acc * 100)\n",
    "print(\"Test Loss : \", frozen_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ms3nVhdYVKzF"
   },
   "outputs": [],
   "source": [
    "img_path = 'data1/test/cats/1989.jpg'\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img = image.load_img(img_path, target_size = (150,150))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255\n",
    "#print (img_tensor.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()\n",
    "\n",
    "from keras.models import load_model\n",
    "model_loaded = load_model('CatsAndDogs.hdf5')\n",
    "from keras import models\n",
    "print(model_loaded.layers)\n",
    "layer_outputs = []\n",
    "for layer in model_loaded.layers[:8]:\n",
    "    layer_outputs.append(layer.output)\n",
    "#layer_outputs = [layer.ouput for layer in model_loaded.layers[:8]]\n",
    "\n",
    "activation_model = models.Model(inputs=model_loaded.input, outputs= layer_outputs)\n",
    "activations = activation_model.predict(img_tensor)\n",
    "\n",
    "first_layer_activation = activations[0]\n",
    "#print (first_layer_activation.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(first_layer_activation[0,:,:,4], cmap = 'viridis' )\n",
    "plt.matshow(first_layer_activation[0,:,:,7], cmap = 'viridis' )\n",
    "\n",
    "layer_names = []\n",
    "for layer in model_loaded.layers[:8]:\n",
    "    layer_names.append(layer.name)\n",
    "print (layer_names)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROL7QBihYmYV"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "model=load_model('CatsAndDogs.hdf5')  \n",
    "\n",
    "def deprocess_image(x):\n",
    "    x-=x.mean()\n",
    "    x/=(x.std()+1e-5)\n",
    "    x*=0.1\n",
    "    x+=0.5\n",
    "    x=np.clip(x,0,1)\n",
    "    x*=255\n",
    "    #Clip to [0,255] and convert to unsigned byte channels\n",
    "    x=np.clip(x,0,255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def generate_pattern(layer_name,filter_index,size=150):\n",
    "    #Define Output and Loss\n",
    "    layer_output=model.get_layer(layer_name).output\n",
    "    loss=K.mean(layer_output[:,:,:,filter_index])\n",
    "    #Compute the gradient of the input with respect to loss\n",
    "    grads=K.gradients(loss,model.input)[0]\n",
    "    grads/=((K.sqrt(K.mean(K.square(grads))))+1e-5)\n",
    "    iterate=K.function([model.input], [loss,grads])\n",
    "    input_img_data=np.random.random((1,size,size,3))*20+128\n",
    "   \n",
    "    step=1\n",
    "    for i in range(100):\n",
    "        loss_value,grads_value=iterate([input_img_data])\n",
    "        input_img_data+=grads_value*step\n",
    "       \n",
    "    img=input_img_data[0]\n",
    "    return deprocess_image(img)\n",
    "\n",
    "\n",
    "layer_names=[]\n",
    "conv_ly1=model.layers[0].name\n",
    "layer_names.append(conv_ly1)\n",
    "conv_ly2=model.layers[2].name\n",
    "layer_names.append(conv_ly2)\n",
    "conv_ly3=model.layers[4].name\n",
    "layer_names.append(conv_ly3)\n",
    "\n",
    "\n",
    "#layer_outputs=[layer.output for layer in model.layers[:8]]\n",
    "\n",
    "k=0\n",
    "#for layer_name,layer in zip(layer_names,model.layers[i]):\n",
    "for layer_name in layer_names:\n",
    "    layer=model.layers[k]\n",
    "    layer_output=layer.output\n",
    "    print(layer_output.shape)\n",
    "    size=int(layer_output.shape[1])\n",
    "    row=8\n",
    "    col=int(layer_output.shape[3]//row)\n",
    "    results=np.zeros((row*size,col*size,3)).astype('uint0')\n",
    "   \n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            filter_img=generate_pattern(layer_name,i+(j*8),size=size)        \n",
    "            horizontal_start=i*size\n",
    "            horizontal_end=horizontal_start+size\n",
    "            vertical_start=j*size\n",
    "            vertical_end=vertical_start+size\n",
    "            results[horizontal_start:horizontal_end,vertical_start:vertical_end,:]=filter_img[:,:,:]\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.title(layer_name)\n",
    "    plt.imshow(results)\n",
    "    k+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SIc4BCJZFSZ"
   },
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "modelvgg_froz.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "history_vgg_unfrozen=modelvgg_froz.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps_per_epoch\n",
    ")\n",
    "modelvgg_froz.save('CatsAndDogs_unfrozen.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3M6zXT0Zqfw"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hist_dict = history_vgg_unfrozen.history\n",
    "print(hist_dict.keys())\n",
    "loss_values = hist_dict['loss']\n",
    "val_loss_values = hist_dict['val_loss']\n",
    "epochs = range(1, len(hist_dict['val_loss']) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Unfrozen_loss.png')\n",
    "\n",
    "plt.clf()\n",
    "acc_values = hist_dict['acc']\n",
    "val_acc_values = hist_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training Acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation Acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Unfrozen_acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7W4Sj5ErZq5u"
   },
   "outputs": [],
   "source": [
    "# Test Eval\n",
    "unfroz_test_loss, unfroz_test_acc = modelvgg_froz.evaluate_generator(\n",
    "    test_generator,\n",
    "    steps=test_steps_per_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "idd2HyovZy_C"
   },
   "outputs": [],
   "source": [
    "# Test Plot\n",
    "print(\"Test Accuracy : \", unfroz_test_acc)\n",
    "print(\"Test Loss : \", unfroz_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbJb6pxzZ3xl"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "\n",
    "# val_gen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True\n",
    "#     )\n",
    "\n",
    "# test_gen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True\n",
    "#     )\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150,150),batch_size=32,class_mode=\"binary\")\n",
    "\n",
    "\n",
    "# val_generator = train_gen.flow_from_directory(\n",
    "#     '/content/DL4_data/validation',\n",
    "#     target_size=(150, 150),\n",
    "#     batch_size=50,\n",
    "#     class_mode='binary'\n",
    "# )\n",
    "\n",
    "# test_generator = train_gen.flow_from_directory(\n",
    "#     '/content/DL4_data/test',\n",
    "#     target_size=(150, 150),\n",
    "#     batch_size=50,\n",
    "#     class_mode='binary'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-jVd2ZYvapvG"
   },
   "outputs": [],
   "source": [
    "# conv_base = VGG16(\n",
    "#     weights='imagenet',\n",
    "#     include_top=False,\n",
    "#     input_shape=(150,150,3)\n",
    "# )\n",
    "\n",
    "conv_base.trainable = False\n",
    "\n",
    "# modelvgg_froz_da = models.Sequential()\n",
    "# modelvgg_froz_da.add(conv_base)\n",
    "# modelvgg_froz_da.add(layers.Flatten())\n",
    "# modelvgg_froz_da.add(layers.Dropout(0.3))\n",
    "# modelvgg_froz_da.add(layers.Dense(512, activation='relu'))\n",
    "# modelvgg_froz_da.add(layers.Dense(1, activation='sigmoid'))\n",
    "# modelvgg_froz_da.summary()\n",
    "\n",
    "modelvgg_froz.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "    metrics=['acc']\n",
    ")\n",
    "history_vgg_frozen_da=modelvgg_froz.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps_per_epoch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4m33_5CcLRY"
   },
   "outputs": [],
   "source": [
    "modelvgg_froz.save('cats_and_dogs-frozen-da.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-ugAs_CcTi_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hist_dict = history_vgg_frozen_da.history\n",
    "print(hist_dict.keys())\n",
    "loss_values = hist_dict['loss']\n",
    "val_loss_values = hist_dict['val_loss']\n",
    "epochs = range(1, len(hist_dict['val_loss']) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Frozenda_loss.png')\n",
    "\n",
    "plt.clf()\n",
    "acc_values = hist_dict['acc']\n",
    "val_acc_values = hist_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training Acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation Acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Frozenda_acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLwl4jL7cabP"
   },
   "outputs": [],
   "source": [
    "da_test_loss, da_test_acc = modelvgg_froz.evaluate_generator(\n",
    "    test_generator,\n",
    "    steps=test_steps_per_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6t3v3F_Hcfs4"
   },
   "outputs": [],
   "source": [
    "print(\"Test Accuracy : \", da_test_acc)\n",
    "print(\"Test Loss : \", da_test_loss)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CatsandDogs.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
